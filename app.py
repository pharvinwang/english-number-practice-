import streamlit as st
import numpy as np
import tempfile
import os
import re
import random
from gtts import gTTS
from num2words import num2words
from rapidfuzz import fuzz
import speech_recognition as sr
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode

# =========================
# Page & CSS
# =========================
st.set_page_config(page_title="è‹±æ–‡æ•¸å­—è·Ÿè®€ v4.1", layout="centered")
st.markdown("""
<style>
.card {background:#fff;border-radius:20px;padding:24px;margin:16px 0;box-shadow:0 4px 10px rgba(0,0,0,0.08);}
.big-number {font-size:110px;text-align:center;font-weight:bold;}
.center {text-align:center;}
.full-btn button {width:100%;font-size:22px;padding:16px;border-radius:16px;}
.progress {font-size:18px;text-align:center;color:#555;}
</style>
""", unsafe_allow_html=True)

st.markdown("<h1 class='center'>ğŸ‘§ è‹±æ–‡æ•¸å­—è·Ÿè®€ v4.1</h1>", unsafe_allow_html=True)
st.markdown("<p class='center'>è‡ªå‹•æ’­æ”¾è€å¸«ç™¼éŸ³ï¼Œè·Ÿè®€æ¨¡å¼</p>", unsafe_allow_html=True)

# =========================
# Sidebar: è¨­å®š
# =========================
st.sidebar.header("âš™ æ•™å¸«è¨­å®š")
start_n = st.sidebar.number_input("èµ·å§‹æ•¸å­— N", 1, 100, 1)
end_n = st.sidebar.number_input("çµæŸæ•¸å­— S", 1, 100, 20)
score_good = st.sidebar.slider("ğŸŒŸ å¾ˆæ£’é–€æª» (%)", 70, 95, 85)
score_ok = st.sidebar.slider("ğŸ™‚ æ¥è¿‘é–€æª» (%)", 50, 84, 70)

# =========================
# Session State Init
# =========================
def init_follow():
    st.session_state.follow_numbers = list(range(start_n, end_n + 1))
    st.session_state.follow_index = 0
    st.session_state.follow_finished = False
    st.session_state.feedback = ""
    st.session_state.last_score = None
    st.session_state.auto_played = False  # æ˜¯å¦å·²è‡ªå‹•æ’­æ”¾ TTS

if "follow_numbers" not in st.session_state:
    init_follow()

# =========================
# Utils
# =========================
def normalize(text):
    text = text.lower()
    text = re.sub(r"[-]", " ", text)
    text = re.sub(r"[^a-z ]", "", text)
    return text.strip()

def smart_score(target, result):
    target = normalize(target)
    result = normalize(result)
    hit = sum(1 for w in target.split() if w in result)
    return min(100, fuzz.ratio(target, result) + hit * 5)

# =========================
# Audio Processor
# =========================
class AudioRecorder(AudioProcessorBase):
    def __init__(self):
        self.frames = []
    def recv(self, frame):
        self.frames.append(frame.to_ndarray())
        return frame

# =========================
# è·Ÿè®€æ¨¡å¼è‡ªå‹•æ’­æ”¾
# =========================
if st.session_state.follow_finished:
    st.markdown("<div class='card center'>", unsafe_allow_html=True)
    st.markdown("ğŸ‰ è·Ÿè®€å®Œæˆï¼å¤ªæ£’äº†ï¼")
    if st.button("é‡æ–°é–‹å§‹"):
        init_follow()
    st.markdown("</div>", unsafe_allow_html=True)
    st.stop()

current_number = st.session_state.follow_numbers[st.session_state.follow_index]
target_word = num2words(current_number).replace("-", " ")
st.markdown(f"<div class='progress'>æ•¸å­— {current_number} / {st.session_state.follow_numbers[-1]}</div>", unsafe_allow_html=True)
st.markdown(f"<div class='card'><div class='big-number'>{current_number}</div></div>", unsafe_allow_html=True)

# è‡ªå‹•æ’­æ”¾è€å¸«ç™¼éŸ³ (åªæ’­æ”¾ä¸€æ¬¡)
if not st.session_state.auto_played:
    tts = gTTS(target_word, lang="en")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
        tts.save(f.name)
        st.audio(f.name)
        os.unlink(f.name)
    st.session_state.auto_played = True

# WebRTC éŒ„éŸ³
ctx = webrtc_streamer(key="follow_speech_auto", mode=WebRtcMode.SENDONLY,
                      audio_processor_factory=AudioRecorder,
                      media_stream_constraints={"audio": True, "video": False})

# åˆ¤æ–·å°æœ‹å‹ç™¼éŸ³
if ctx.audio_processor and not ctx.state.playing:
    frames = ctx.audio_processor.frames
    if frames:
        audio = np.concatenate(frames, axis=0)
        import soundfile as sf
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            sf.write(f.name, audio, 48000)
            wav_path = f.name
        recognizer = sr.Recognizer()
        with sr.AudioFile(wav_path) as src:
            audio_data = recognizer.record(src)
        try:
            result = recognizer.recognize_google(audio_data, language="en-US")
        except:
            result = ""
        os.unlink(wav_path)
        score = smart_score(target_word, result)
        st.session_state.last_score = score
        if score >= score_good:
            st.session_state.feedback = "âœ… æ­£ç¢ºï¼"
            st.session_state.follow_index += 1
            st.session_state.auto_played = False  # ä¸‹ä¸€é¡Œå†è‡ªå‹•æ’­æ”¾
            if st.session_state.follow_index >= len(st.session_state.follow_numbers):
                st.session_state.follow_finished = True
        elif score >= score_ok:
            st.session_state.feedback = "ğŸ™‚ å†è©¦ä¸€æ¬¡å°±å¥½ï¼"
        else:
            st.session_state.feedback = "ğŸ’ª æ²’é—œä¿‚ï¼Œå†è©¦ï¼"

# é¡¯ç¤ºå›é¥‹
st.markdown("<div class='card center'>", unsafe_allow_html=True)
if st.session_state.feedback:
    st.markdown(f"<h2 class='center'>{st.session_state.feedback}</h2>", unsafe_allow_html=True)
    if st.session_state.last_score is not None:
        st.markdown(f"<p class='center'>ç™¼éŸ³æ¥è¿‘ç¨‹åº¦ï¼šç´„ {st.session_state.last_score}%</p>", unsafe_allow_html=True)
st.markdown("</div>", unsafe_allow_html=True)
