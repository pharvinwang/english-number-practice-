# app.py v4.7 å®Œæ•´ä¿®æ­£ç‰ˆ
import streamlit as st
from gtts import gTTS
import os
import tempfile
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import numpy as np
import speech_recognition as sr

st.set_page_config(page_title="è‹±æ–‡æ•¸å­—è·Ÿè®€", layout="wide")

# -----------------------------
# SESSION STATE INIT
# -----------------------------
if "mic_on" not in st.session_state:
    st.session_state.mic_on = False
if "current_number" not in st.session_state:
    st.session_state.current_number = 0
if "numbers_list" not in st.session_state:
    st.session_state.numbers_list = []

# -----------------------------
# SIDEBAR: TEACHER SETTINGS
# -----------------------------
st.sidebar.header("ğŸ‘¨â€ğŸ« æ•™å¸«è¨­å®š")
start_num = st.sidebar.number_input("èµ·å§‹æ•¸å­— N", min_value=1, max_value=100, value=1)
end_num = st.sidebar.number_input("çµæŸæ•¸å­— S", min_value=1, max_value=100, value=20)
threshold_high = st.sidebar.slider("ğŸŒŸ å¾ˆæ£’é–€æª» (%)", 70, 95, 85)
threshold_low = st.sidebar.slider("ğŸ™‚ æ¥è¿‘é–€æª» (%)", 50, 90, 70)

mode = st.sidebar.radio("é¸æ“‡æ¨¡å¼", ["é—–é—œæ¨¡å¼", "è·Ÿè®€æ¨¡å¼"])

if "numbers_list" not in st.session_state or st.session_state.numbers_list != list(range(start_num, end_num+1)):
    st.session_state.numbers_list = list(range(start_num, end_num+1))
    st.session_state.current_number = 0

st.sidebar.header("ğŸ¤ éŒ„éŸ³æ§åˆ¶")
if st.sidebar.button("å•Ÿå‹•éŒ„éŸ³"):
    st.session_state.mic_on = True
    st.success("éŒ„éŸ³å·²å•Ÿå‹•ï¼Œè«‹å…è¨±ç€è¦½å™¨ä½¿ç”¨éº¥å…‹é¢¨ã€‚")

# -----------------------------
# WEBRTC INITIALIZATION
# -----------------------------
class AudioRecorder(AudioProcessorBase):
    def __init__(self):
        self.frames = []

    def recv(self, frame):
        if st.session_state.mic_on:
            self.frames.append(frame.to_ndarray())
        return frame

ctx = webrtc_streamer(
    key="mic",
    mode=WebRtcMode.SENDONLY,
    audio_processor_factory=AudioRecorder,
    media_stream_constraints={"audio": True, "video": False},
    async_processing=True
)

# -----------------------------
# MAIN AREA
# -----------------------------
st.title("ğŸ‘§ è‹±æ–‡æ•¸å­—è·Ÿè®€ v4.7")
st.caption("å·¦å´è¨­å®š â†’ å•Ÿå‹•éŒ„éŸ³ â†’ æ’­æ”¾è€å¸«ç™¼éŸ³ â†’ è·Ÿè®€ â†’ æäº¤")

if st.session_state.current_number < len(st.session_state.numbers_list):
    number = st.session_state.numbers_list[st.session_state.current_number]
    st.subheader(f"æ•¸å­— {st.session_state.current_number+1} / {len(st.session_state.numbers_list)}")
    st.markdown(f"<h1 style='text-align:center;'>{number}</h1>", unsafe_allow_html=True)
else:
    st.success("ğŸ‰ æœ¬è¼ªç·´ç¿’å®Œæˆï¼")

# -----------------------------
# FUNCTIONS
# -----------------------------
def play_teacher_voice(num):
    tts = gTTS(text=str(num), lang="en")
    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    tts.save(tmp_file.name)
    st.audio(tmp_file.name)
    tmp_file.close()
    os.unlink(tmp_file.name)

def submit_recording():
    if not st.session_state.mic_on or ctx.audio_receiver is None:
        st.warning("âš ï¸ å°šæœªéŒ„éŸ³æˆ–éŒ„éŸ³ç„¡æ•ˆï¼")
        return
    frames = ctx.audio_processor.frames
    if len(frames) == 0:
        st.warning("âš ï¸ å°šæœªéŒ„éŸ³æˆ–éŒ„éŸ³ç„¡æ•ˆï¼")
        return
    # ä¿å­˜éŒ„éŸ³
    audio_array = np.concatenate(frames, axis=0)
    tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    from scipy.io.wavfile import write
    write(tmp_file.name, 16000, audio_array)
    # èªéŸ³è¾¨è­˜
    recognizer = sr.Recognizer()
    with sr.AudioFile(tmp_file.name) as source:
        audio = recognizer.record(source)
        try:
            text = recognizer.recognize_google(audio)
            st.info(f"è¾¨è­˜çµæœï¼š{text}")
            if str(number) in text or str(number) in text.lower():
                st.success("âœ… ç™¼éŸ³æ­£ç¢ºï¼")
                st.session_state.current_number += 1
            else:
                st.warning("âŒ ç™¼éŸ³å¯èƒ½ä¸æ­£ç¢ºï¼Œè«‹å†è©¦ä¸€æ¬¡ï¼")
        except:
            st.warning("âš ï¸ ç„¡æ³•è¾¨è­˜éŒ„éŸ³")
    tmp_file.close()
    os.unlink(tmp_file.name)
    ctx.audio_processor.frames = []  # æ¸…ç©ºéŒ„éŸ³ç·©å­˜

# -----------------------------
# BUTTONS
# -----------------------------
col1, col2 = st.columns([1,1])
with col1:
    if st.button("æ’­æ”¾è€å¸«ç™¼éŸ³"):
        play_teacher_voice(number)

with col2:
    if st.button("æäº¤éŒ„éŸ³"):
        submit_recording()
