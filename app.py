import streamlit as st
import numpy as np
import tempfile
import os
import re
import random
from gtts import gTTS
from num2words import num2words
from rapidfuzz import fuzz
import speech_recognition as sr
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode

# =========================
# Page & CSS
# =========================
st.set_page_config(page_title="è‹±æ–‡æ•¸å­—è·Ÿè®€ v4.6", layout="centered")
st.markdown("""
<style>
.card {background:#fff;border-radius:20px;padding:24px;margin:16px 0;box-shadow:0 4px 10px rgba(0,0,0,0.08);}
.big-number {font-size:110px;text-align:center;font-weight:bold;}
.center {text-align:center;}
.progress {font-size:18px;text-align:center;color:#555;}
</style>
""", unsafe_allow_html=True)

st.markdown("<h1 class='center'>ğŸ‘§ è‹±æ–‡æ•¸å­—è·Ÿè®€ v4.6</h1>", unsafe_allow_html=True)
st.markdown("<p class='center'>å·¦å´è¨­å®š â†’ å•Ÿå‹•éŒ„éŸ³ â†’ æ’­æ”¾è€å¸«ç™¼éŸ³ â†’ è·Ÿè®€ â†’ æäº¤</p>", unsafe_allow_html=True)

# =========================
# Sidebar: è¨­å®š + START
# =========================
st.sidebar.header("âš™ æ•™å¸«è¨­å®š")
start_n = st.sidebar.number_input("èµ·å§‹æ•¸å­— N", 1, 100, 1)
end_n = st.sidebar.number_input("çµæŸæ•¸å­— S", 1, 100, 20)
score_good = st.sidebar.slider("ğŸŒŸ å¾ˆæ£’é–€æª» (%)", 70, 95, 85)
score_ok = st.sidebar.slider("ğŸ™‚ æ¥è¿‘é–€æª» (%)", 50, 84, 70)
mode = st.sidebar.radio("é¸æ“‡æ¨¡å¼", ["é—–é—œæ¨¡å¼", "è·Ÿè®€æ¨¡å¼"])

if "start_pressed" not in st.session_state:
    st.session_state.start_pressed = False
if st.sidebar.button("START"):
    st.session_state.start_pressed = True

# =========================
# Sidebar: éŒ„éŸ³æ§åˆ¶
# =========================
st.sidebar.header("ğŸ¤ éŒ„éŸ³æ§åˆ¶")
if "mic_on" not in st.session_state:
    st.session_state.mic_on = False
if st.sidebar.button("å•Ÿå‹•éŒ„éŸ³"):
    st.session_state.mic_on = True
    if "ctx_follow" not in st.session_state:
        class AudioRecorder(AudioProcessorBase):
            def __init__(self):
                self.frames = []
            def recv(self, frame):
                self.frames.append(frame.to_ndarray())
                return frame
        st.session_state.ctx_follow = webrtc_streamer(
            key="follow_speech",
            mode=WebRtcMode.SENDONLY,
            audio_processor_factory=AudioRecorder,
            media_stream_constraints={"audio": True, "video": False},
            async_processing=True
        )
    st.session_state.frames_follow = []

# =========================
# Utils
# =========================
def normalize(text):
    text = text.lower()
    text = re.sub(r"[-]", " ", text)
    text = re.sub(r"[^a-z ]", "", text)
    return text.strip()

def smart_score(target, result):
    target = normalize(target)
    result = normalize(result)
    hit = sum(1 for w in target.split() if w in result)
    return min(100, fuzz.ratio(target, result) + hit * 5)

# =========================
# Init Functions
# =========================
def init_challenge():
    st.session_state.challenge_numbers = random.sample(range(start_n, end_n + 1), 10)
    st.session_state.challenge_index = 0
    st.session_state.challenge_correct = 0
    st.session_state.challenge_finished = False
    st.session_state.feedback = ""
    st.session_state.last_score = None
    if "ctx_challenge" not in st.session_state:
        class AudioRecorder(AudioProcessorBase):
            def __init__(self):
                self.frames = []
            def recv(self, frame):
                self.frames.append(frame.to_ndarray())
                return frame
        st.session_state.ctx_challenge = webrtc_streamer(
            key="challenge_speech",
            mode=WebRtcMode.SENDONLY,
            audio_processor_factory=AudioRecorder,
            media_stream_constraints={"audio": True, "video": False},
            async_processing=True
        )
    st.session_state.frames_challenge = []

def init_follow():
    st.session_state.follow_numbers = list(range(start_n, end_n + 1))
    st.session_state.follow_index = 0
    st.session_state.follow_finished = False
    st.session_state.feedback = ""
    st.session_state.last_score = None
    st.session_state.tts_played = False
    if "ctx_follow" not in st.session_state and st.session_state.mic_on:
        class AudioRecorder(AudioProcessorBase):
            def __init__(self):
                self.frames = []
            def recv(self, frame):
                self.frames.append(frame.to_ndarray())
                return frame
        st.session_state.ctx_follow = webrtc_streamer(
            key="follow_speech",
            mode=WebRtcMode.SENDONLY,
            audio_processor_factory=AudioRecorder,
            media_stream_constraints={"audio": True, "video": False},
            async_processing=True
        )
    st.session_state.frames_follow = []

# =========================
# START æ§åˆ¶
# =========================
if not st.session_state.start_pressed:
    st.markdown("<p class='center'>è«‹å…ˆè¨­å®šå·¦å´åƒæ•¸ä¸¦æŒ‰ START</p>", unsafe_allow_html=True)
    st.stop()

if mode == "é—–é—œæ¨¡å¼":
    if "challenge_numbers" not in st.session_state:
        init_challenge()
elif mode == "è·Ÿè®€æ¨¡å¼":
    if "follow_numbers" not in st.session_state:
        init_follow()

# =========================
# TTS æ’­æ”¾
# =========================
if "tts_files" not in st.session_state:
    st.session_state.tts_files = {}

def play_tts(number):
    if number not in st.session_state.tts_files:
        word = num2words(number).replace("-", " ")
        tts = gTTS(word, lang="en")
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
            tts.save(f.name)
            st.session_state.tts_files[number] = f.name
    st.audio(st.session_state.tts_files[number])

# =========================
# Mode: è·Ÿè®€æ¨¡å¼
# =========================
if mode == "è·Ÿè®€æ¨¡å¼":
    if st.session_state.follow_finished:
        st.markdown(f"ğŸ‰ è·Ÿè®€å®Œæˆï¼å¤ªæ£’äº†ï¼")
        if st.button("é‡æ–°é–‹å§‹"):
            init_follow()
        st.stop()

    current_number = st.session_state.follow_numbers[st.session_state.follow_index]
    st.markdown(f"æ•¸å­— {current_number} / {st.session_state.follow_numbers[-1]}")
    st.markdown(f"<h1>{current_number}</h1>", unsafe_allow_html=True)

    col1, col2 = st.columns([1,3])
    with col1:
        if st.button("æ’­æ”¾è€å¸«ç™¼éŸ³", key=f"play_{current_number}"):
            play_tts(current_number)

    if st.session_state.mic_on:
        ctx = st.session_state.ctx_follow
        if ctx.audio_processor:
            st.session_state.frames_follow += ctx.audio_processor.frames
            ctx.audio_processor.frames = []

    if st.button("æäº¤éŒ„éŸ³", key=f"submit_{current_number}"):
        if st.session_state.mic_on and st.session_state.frames_follow:
            audio = np.concatenate(st.session_state.frames_follow, axis=0)
            import soundfile as sf
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                sf.write(f.name, audio, 48000)
                wav_path = f.name
            recognizer = sr.Recognizer()
            with sr.AudioFile(wav_path) as src:
                audio_data = recognizer.record(src)
            try:
                result = recognizer.recognize_google(audio_data, language="en-US")
            except:
                result = ""
            os.unlink(wav_path)
            st.session_state.frames_follow = []

            score = smart_score(num2words(current_number).replace("-", " "), result)
            st.session_state.last_score = score
            if score >= score_good:
                st.session_state.feedback = "âœ… æ­£ç¢ºï¼"
                st.session_state.follow_index += 1
                if st.session_state.follow_index >= len(st.session_state.follow_numbers):
                    st.session_state.follow_finished = True
            elif score >= score_ok:
                st.session_state.feedback = "ğŸ™‚ å†è©¦ä¸€æ¬¡å°±å¥½ï¼"
            else:
                st.session_state.feedback = "ğŸ’ª å†è©¦ï¼"
        else:
            st.session_state.feedback = "âš ï¸ å°šæœªéŒ„éŸ³æˆ–éŒ„éŸ³ç„¡æ•ˆï¼"

    st.markdown(st.session_state.feedback)

# =========================
# Mode: é—–é—œæ¨¡å¼
# =========================
elif mode == "é—–é—œæ¨¡å¼":
    if st.session_state.challenge_finished:
        st.markdown(f"ğŸ‰ é—–é—œå®Œæˆï¼æ­£ç¢ºé¡Œæ•¸ï¼š{st.session_state.challenge_correct}/10")
        if st.button("é‡æ–°é–‹å§‹"):
            init_challenge()
        st.stop()

    current_number = st.session_state.challenge_numbers[st.session_state.challenge_index]
    st.markdown(f"é¡Œç›® {st.session_state.challenge_index+1} / 10")
    st.markdown(f"<h1>{current_number}</h1>", unsafe_allow_html=True)

    col1, col2 = st.columns([1,3])
    with col1:
        if st.button("æ’­æ”¾è€å¸«ç™¼éŸ³", key=f"play_ch_{current_number}"):
            play_tts(current_number)

    if st.session_state.mic_on:
        ctx = st.session_state.ctx_challenge
        if ctx.audio_processor:
            st.session_state.frames_challenge += ctx.audio_processor.frames
            ctx.audio_processor.frames = []

    if st.button("æäº¤éŒ„éŸ³", key=f"submit_ch_{current_number}"):
        if st.session_state.mic_on and st.session_state.frames_challenge:
            audio = np.concatenate(st.session_state.frames_challenge, axis=0)
            import soundfile as sf
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                sf.write(f.name, audio, 48000)
                wav_path = f.name
            recognizer = sr.Recognizer()
            with sr.AudioFile(wav_path) as src:
                audio_data = recognizer.record(src)
            try:
                result = recognizer.recognize_google(audio_data, language="en-US")
            except:
                result = ""
            os.unlink(wav_path)
            st.session_state.frames_challenge = []

            score = smart_score(num2words(current_number).replace("-", " "), result)
            st.session_state.last_score = score
            if score >= score_good:
                st.session_state.feedback = "âœ… æ­£ç¢ºï¼"
                st.session_state.challenge_correct += 1
            elif score >= score_ok:
                st.session_state.feedback = "ğŸ™‚ å†è©¦ä¸€æ¬¡å°±å¥½ï¼"
            else:
                st.session_state.feedback = "ğŸ’ª å†è©¦ï¼"
            st.session_state.challenge_index += 1
            if st.session_state.challenge_index >= 10:
                st.session_state.challenge_finished = True
        else:
            st.session_state.feedback = "âš ï¸ å°šæœªéŒ„éŸ³æˆ–éŒ„éŸ³ç„¡æ•ˆï¼"

    st.markdown(st.session_state.feedback)
